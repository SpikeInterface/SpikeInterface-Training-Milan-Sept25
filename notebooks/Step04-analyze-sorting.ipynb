{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0245ca6e",
   "metadata": {},
   "source": [
    "We now have a sorter and recording. Great! Now we can get on to the fun stuff: what shape are our unit templates? Which units are correlated with each other? Where on the probe are the units? This require computing extra information. In `SpikeInterface` we do this by creating an object called a `SortingAnalyzer`. \n",
    "\n",
    "A `SortingAnalyzer` combines a recording with a sorting in a unified way, no matter which sorter or recording format you used. Once you have an analyzer, you can compute postprocessing _extensions_ (like spike locations, waveforms, template metrics, ...) in exactly the same for every sorter. They can also be used to keep track of curation, merging and splitting, and more.\n",
    "\n",
    "This unified framework has several benefits. The main one is that the analyzer defines a sorter-agnostic format for post-sorting analysis. Hence:\n",
    "- You can compare sorters on a level playing field (i.e. all the extensions are computed in the same way, for all sorters)\n",
    "- Your postprocessing pipeline can be identical, whether using mountainsort to sort tetrode data or kilosort to sort NeuroPixel data, creating a unified pipeline in your lab.\n",
    "- External tools have a simple starting point to work from. This should make tooling in the community easier, and there are already several examples of this:\n",
    "  - NeuronConv contains a `SortingAnalyzerToNWB` function\n",
    "  - spikeinterface-gui, sortingview and UnitMatch can take an analyzer as their initial input.\n",
    "  - UnitRefine\n",
    "\n",
    "Hopefully you're now convinced that creating a `SortingAnalyzer` will make your life easier, and smooth the path to using new tools in your analysis pipeline. So, let's make one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a95c0f-d4de-4c1e-9a36-fd40703ff747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "from pathlib import Path\n",
    "\n",
    "si.set_global_job_kwargs(n_jobs=4)\n",
    "base_folder = Path(\"/home/nolanlab/Work/Projects/Milan/\")\n",
    "\n",
    "recording, sorting = si.generate_ground_truth_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d39ec6-41cd-4c53-829b-9ffd79d1033f",
   "metadata": {},
   "source": [
    "When you make the analyzer, you can either make in _in memory_ or _in folder_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da113b7-ca09-42f5-992b-8359cb707ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_in_memory = si.create_sorting_analyzer(\n",
    "    sorting=sorting,\n",
    "    recording=recording, \n",
    ")\n",
    "\n",
    "analyzer_in_folder = si.create_sorting_analyzer(\n",
    "    sorting=sorting, \n",
    "    recording=recording, \n",
    "    folder=\"my_analyzer\",\n",
    "    format=\"binary_folder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8314d5-ed33-42af-b6ba-6a83ad92119b",
   "metadata": {},
   "source": [
    "When in memory, the analyzer is stored in RAM. This makes computation faster, but will use more RAM. You can save your `analyzer_in_memory` to a folder at any point using `analyzer_in_memory.save_as`. (more info: https://spikeinterface.readthedocs.io/en/stable/modules/postprocessing.html) For this demo, we'll use the folder analyzer. Go take a look in the folder. You'll see that it contains recording information, sorting information and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c33ae-18ee-4c9d-b663-acca3aa343d7",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "\n",
    "Each thing-you'd-like-to-compute is stored as an Extention of the analyzer. Let's compute the templates: the averaged waveforms from all (or a large random sample of) individual spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b07fd-d96f-4d52-8728-87162dc58f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_in_folder.compute(\"templates\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2291d580-fac6-4e35-8805-e5ebd9299f6a",
   "metadata": {},
   "source": [
    "Oh no - an error! This is due to the fact that extensions depend on each other. For example, you can't template similarity (how similar unit templates are to one another) without computing templates. The full dependency graph can be seen here:\n",
    "\n",
    "![image](images/parent_child.svg)\n",
    "\n",
    "So, when we compute extensions we need to know which _other_ extensions we need to compute beforehand... Let's compute a few. You can either compute one at a time, or give the `analyzer` a big dictionary of extensions (recommended! It will re-sort based on dependencies, and be able to do a few time saving tricks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d5e99-6f7e-4047-9581-4bbec0e202a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just one\n",
    "analyzer_in_folder.compute(\"random_spikes\")\n",
    "\n",
    "# or lots: here we also specify some kwargs\n",
    "analyzer_in_folder.compute({\n",
    "    \"templates\": {},\n",
    "    \"correlograms\": {},\n",
    "    \"noise_levels\": {'method': 'std'},\n",
    "    \"spike_amplitudes\": {},\n",
    "    \"template_metrics\": {'include_multi_channel_metrics': True},\n",
    "    \"unit_locations\": {},\n",
    "    \"quality_metrics\": {},\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8e7d4-e66b-43dd-8d85-004d0733779d",
   "metadata": {},
   "source": [
    "> **Note**: to see which extensions are availbale to compute, use `analyzer_in_folder.get_computable_extensions()`. A good way to see which arguments an extension accepts, you can use e.g. `analyzer_in_folder.get_default_extension_params('template_metrics')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac7f1e-0baf-486c-a1de-b189086fe15b",
   "metadata": {},
   "source": [
    "Now take another look in your analyzer folder. You'll find lots of new folders containing your extensions! You can load this data directly, but `SpikeInterface` contains a lot of handy loader functions. The notation is always `analyzer.get_extension(\"extension_name\").get_data()`. Let's look at the quality metrics. These are measures of how _good_ a unit is (more details: https://spikeinterface.readthedocs.io/en/latest/modules/qualitymetrics.html) Note that which quality metrics are computed depends on which other extensions you've computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ccc9e-9fb5-4734-87a0-50ac4999d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics = analyzer_in_folder.get_extension(\"quality_metrics\").get_data()\n",
    "quality_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e351cf-c1f9-4dc6-a18b-baf06988f757",
   "metadata": {},
   "source": [
    "This is a `pandas` dataframe with information about each unit. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e732ee-2992-42a8-bd2d-b7dc62e7cacc",
   "metadata": {},
   "source": [
    "`SpikeInterface` also supports lots of plotting functions that are related to extensions (see more: https://spikeinterface.readthedocs.io/en/latest/modules/widgets.html#available-plotting-functions). Let's plot the spike locations, then a summary plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7328f-2b49-444b-b8b2-9c95b1d503ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_amplitudes(analyzer_in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724836c-e6b7-4f3b-ab82-6618cb81e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_summary(analyzer_in_folder, unit_id=\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935620f-19cd-4f9e-8d90-a977fbb2579b",
   "metadata": {},
   "source": [
    "The analyzer is key to playing with your data. So we'll now do somes exercises to help us explore it more. To do these tasks you'll need some basic `numpy` and `pandas` skills. For numpy, this page might help (https://numpy.org/doc/stable/user/absolute_beginners.html#indexing-and-slicing). For pandas, maybe this: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html. Or ask someone! \n",
    "\n",
    "**Exercise 1**: Get the signal-to-noise ratio (\"snr\" quality metric) for all units and plot an histogram \n",
    "\n",
    "**Exercise 2**: Plot the auto-correlogram (using `plot_autocorrelograms`) of the unit with the worst \"isi_violations_ratio\" \n",
    "\n",
    "**Exercise 3**: use the SI API to find which the channel has the extremal template (hint: `get_template_extremum_channel`). Then use this information and `matplotlib` to plot the template on the extremal channel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
